---
title: "STA141A Final"
subtitle: "STA141A | Fall 2022 | KÃ¼hnert"
author: "Alvin Akpokli, Sarvesh Krishan, Ngai Pan Ng, Hannah Spray"
date: "7 December 2022"
output: 
  pdf_document:
    keep_md: true
    extra_dependencies: ["amsmath"]
fontsize: 10pt
---

# Project Overview  
This project aims to investigate possible risk factors for death due to heart failure.  

## Group 4 members:  
- Alvin Akpokli (akakpokli@ucdavis.edu)
- Sarvesh Krishan (skrishan@ucdavis.edu)
- Ngai Pan Ng (npng@ucdavis.edu)
- Hannah Spray (hgspray@ucdavis.edu)

## Research questions of interest:  
1. Is death from heart failure significantly more prevalent in those with high blood pressure (i.e. hypertension)?
2.  Is death from heart failure significantly more prevalent in men or women that smoke versus those who do not?

## Dataset:  
Our dataset is called "Heart failure clinical records dataset". This dataset was obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records). This dataset contains both boolean and numerical variables:  
  
- age: age of the patient (years) 
- anaemia: decrease of red blood cells or hemoglobin (boolean)
- high blood pressure: if the patient has hypertension (boolean)
- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)
- diabetes: if the patient has diabetes (boolean)
- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)
- platelets: platelets in the blood (kiloplatelets/mL)
- sex: woman or man (binary)
- serum creatinine: level of serum creatinine in the blood (mg/dL)
- serum sodium: level of serum sodium in the blood (mEq/L)
- smoking: if the patient smokes or not (boolean)
- time: follow-up period (days)
- [target] death event: if the patient deceased during the follow-up period (boolean)  
  
We will treat "death event" as our binary response variable $Y$, where  
\[
Y = \begin{cases}
1 & \text{if patient } i \text{ deceased during the follow-up period} \\
0 & \text{otherwise}
\end{cases}
\]

## Method:  
We plan to conduct our analyses as a classification problem, using a logistic regression model. We will create a model that expresses the log-odds of a patient being deceased during the follow-up period as a function of our predictor variables. Our goals for these fitted models are:  
1. To determine whether or not high blood pressure (hypertension) increases the probability of a patient being deceased during the follow-up period  
2. To determine whether or not _____ blaha lhah?


# Diagnostics

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
packages = c("knitr", "ggplot2", "kableExtra", "dplyr", "corrplot", "car", "ISLR")
lapply(packages, library, character.only = TRUE)
```

```{r loadData, echo = FALSE}
# make sure csv file is in working directory
data = read.csv("heart_failure_clinical_records_dataset.csv")
attach(data)
```

## Logistic Regression Model Assumptions
  
We can begin our analysis by verifying that our dataset meets the model assumptions for logistic regression:  
1. dependent variable is binary  
2. observations are independent  
3. little to no multicollinearity between predictor variables  
  
We already know that our dependent variable, 'DEATH_EVENT' is binary - it will equal 1 if the given patient deceased during the follow-up period, and 0 otherwise. Regarding independence between observations, we can assume that this assumption is met through the study design - i.e. the sampling procedure used for this dataset utilized independent random sampling (<- humus just wrote this part and is not sure if this is actually true).  

To check the assumption regarding multicollinearity between predictor variables, we can utilize the variance inflation factor (VIF) to detect multicollinearity in our model. We begin by creating our "full model", regressing our response variable (DEATH_EVENT) with all of the predictor variables:  


```{r fullModel, echo = 3}
# start with full model:
# i.e. regress response with all predictor variables
full_model = glm(DEATH_EVENT ~ ., family = "binomial", data = data)

```

And investigate the VIF for each predictor variable:

```{r multicollinearity}
# checking for (multi)collinearity:
# using VIF:
kable(vif(full_model), digits = 4,
      caption = "Table 1: VIF for predictors",
      col.names = c("VIF")) %>%
  kable_styling(latex_options = "HOLD_position")

# note:
# for VIF we will need to decide on a "threshold" for which VIF values are deemed too high for including a predictor in our model.
# statology says that generally, predictors with VIF>5 indicates potential strong correlation between that predictor and the other predictors ... but all of our VIFs in this case are less than 2 so we will need to figure out another threshold
# read more: 
# https://www.statology.org/variance-inflation-factor-r/
# https://www.statology.org/multicollinearity-regression/
# https://www.statology.org/glm-r-squared/
# lecture #13 slide 14/14 - kuhnert

# # using correlation matrix:
# corrMatrix = kable(cor(data), digits = 4)
# 
# # using correlation plot:
# # base R:
# pairs(data, upper.panel = NULL)
# # using corrplot package:
# corrplot(cor(data), type = 'lower')
```  
For the purposes of this analysis, we can use the general rule of thumb which states that predictor variables with VIF values greater than 5 should be treated as problematic. We can see by looking at the table above that none of the predictor variables in the fitted model have VIF values greater than 5; in fact, all of the values are between 1 and 2. Hence, we can proceed without having to remedy multicollinearity. 

  
  
some plots:
```{r, fig.align = 'center', fig.height = 5, fig.width = 5}
ggplot(data = data,
       aes(x = as.factor(DEATH_EVENT), fill = as.factor(high_blood_pressure))) +
  geom_bar() +
  labs(title = "number of patients deceased during follow-up period", 
       subtitle = "by whether or not patient has high blood pressure") + 
  scale_x_discrete(labels = setNames(c("not deceased", "deceased"), c(0, 1))) + 
  scale_fill_discrete(name = "high blood pressure",
                      labels = c("no", "yes"))
  


```

# Model Fitting  
## Hypothesis Testing



# Discussion  

\pagebreak
# References  
Davide Chicco, Giuseppe Jurman: "Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone". BMC Medical Informatics and Decision Making 20, 16 (2020).
